{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: nvidia-smi: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_size -> 5.0\n",
      "\t\tgoal_speed -> 1.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='Reacher_Linux_NoVis/Reacher.x86_64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "env = UnityEnvironment(file_name='Reacher_Linux_NoVis/Reacher.x86_64')\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "env_info = env.reset(train_mode=True)[brain_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Size of each action: 4\n",
      "episode done  [False]\n",
      "There are 1 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726671e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "print(\"episode done \",env_info.local_done)\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_size -> 5.0\n",
      "\t\tgoal_speed -> 1.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from unityagents import UnityEnvironment\n",
    "from config import Config\n",
    "from model2 import Actor, Critic\n",
    "from memory import ReplayBuffer\n",
    "from noise import OUNoise\n",
    "from agent1 import DDPGAgent\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "env = UnityEnvironment(file_name='Reacher_Linux_NoVis/Reacher.x86_64')\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "\n",
    "config = Config()\n",
    "\n",
    "config.seed = 2\n",
    "config.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "config.action_size = brain.vector_action_space_size\n",
    "config.states = env_info.vector_observations\n",
    "config.state_size = config.states.shape[1]\n",
    "config.num_agents = len(env_info.agents)\n",
    "\n",
    "config.actor_hidden_units = (512, 256)\n",
    "config.actor_learning_rate = 1e-4\n",
    "config.actor_network_fn = lambda: Actor(config.action_size, config.state_size, config.actor_hidden_units, config.seed).to(config.device)\n",
    "config.actor_optimizer_fn = lambda params: torch.optim.Adam(params, lr=config.actor_learning_rate)\n",
    "\n",
    "config.critic_hidden_units = (512, 256)\n",
    "config.critic_learning_rate = 3e-4\n",
    "config.weight_decay = 0\n",
    "config.critic_network_fn = lambda: Critic(config.action_size, config.state_size, config.critic_hidden_units, config.seed).to(config.device)\n",
    "config.critic_optimizer_fn = lambda params: torch.optim.Adam(params, lr=config.critic_learning_rate)\n",
    "\n",
    "config.batch_size = 512\n",
    "config.buffer_size = int(1e6)\n",
    "config.discount = 0.99\n",
    "config.update_every = 4\n",
    "config.memory_fn = lambda: ReplayBuffer(config.action_size, config.buffer_size, config.batch_size, config.seed, config.device)\n",
    "\n",
    "config.noise_fn = lambda: OUNoise(config.action_size, config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[922]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_info.agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DDPGAgent(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpg(n_episodes=5000, max_t=2000):\n",
    "    all_scores = []\n",
    "    scores_window = deque(maxlen=100)\n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        \n",
    "        agent.reset()\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations           \n",
    "        scores = np.zeros(config.num_agents)\n",
    "\n",
    "        for _ in range(max_t):\n",
    "            actions = agent.act(states)\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            rewards = env_info.rewards\n",
    "            next_states = env_info.vector_observations\n",
    "            dones = env_info.local_done\n",
    "\n",
    "            agent.step(states, actions, rewards, next_states, dones)\n",
    "\n",
    "            scores += rewards\n",
    "            states = next_states\n",
    "                \n",
    "        avg_score = np.mean(scores)\n",
    "        scores_window.append(avg_score)\n",
    "        all_scores.append(avg_score)\n",
    "        \n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=30.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "            break \n",
    "            \n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home_01/f20150198/miniconda2/envs/python3/lib/python3.5/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3\tAverage Score: 0.31"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a85c8c698ef5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mddpg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# plot the scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m111\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-dfae3254f22b>\u001b[0m in \u001b[0;36mddpg\u001b[0;34m(n_episodes, max_t)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mdones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/deep-reinforcement-learning/p2_continuous-control/agent1.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, states, actions, rewards, next_states, dones)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0mexperiences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/deep-reinforcement-learning/p2_continuous-control/agent1.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, experiences, gamma)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m# Minimize the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mcritic_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_local\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/python3/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/python3/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores = ddpg()\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n",
      "[0.0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a11aa47212dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_agents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# select an action (for each agent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m                  \u001b[0;31m# all actions between -1 and 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0menv_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[0;34m]\u001b[0m           \u001b[0;31m# send all actions to tne environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mnext_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_observations\u001b[0m         \u001b[0;31m# get next state (for each agent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m                         \u001b[0;31m# get reward (for each agent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/python3/lib/python3.5/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, vector_action, memory, text_action)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             outputs = self.communicator.exchange(\n\u001b[0;32m--> 369\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_step_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m             )\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/python3/lib/python3.5/site-packages/unityagents/rpc_communicator.py\u001b[0m in \u001b[0;36mexchange\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/python3/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/python3/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/python3/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    print(rewards)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_size -> 5.0\n",
      "\t\tgoal_speed -> 1.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of each action: 4\n",
      "episode done  [False]\n",
      "hello\n",
      "[[0.1433571  0.21182206 0.02547583 0.06196284]]\n",
      "[0.0]\n",
      "[[0.28165898 0.3304662  0.15777989 0.12106409]]\n",
      "[0.0]\n",
      "[[0.35316113 0.40545145 0.25254792 0.14139797]]\n",
      "[0.0]\n",
      "[[0.37870696 0.42656898 0.3614611  0.32598722]]\n",
      "[0.0]\n",
      "[[0.50384283 0.47476628 0.39850992 0.33766338]]\n",
      "[0.0]\n",
      "[[0.4273956  0.41241902 0.4341423  0.35768384]]\n",
      "[0.0]\n",
      "[[0.43123418 0.53234977 0.4765858  0.4231666 ]]\n",
      "[0.0]\n",
      "[[0.4056642  0.46072778 0.47251487 0.39401457]]\n",
      "[0.0]\n",
      "[[0.43882784 0.59475094 0.5389058  0.37823108]]\n",
      "[0.0]\n",
      "[[0.54357624 0.6682625  0.60739136 0.509707  ]]\n",
      "[0.0]\n",
      "[[0.60645807 0.72936064 0.589432   0.636395  ]]\n",
      "[0.0]\n",
      "[[0.69959223 0.65556335 0.65405643 0.6909759 ]]\n",
      "[0.0]\n",
      "[[0.6785864  0.6667204  0.65631133 0.77915543]]\n",
      "[0.0]\n",
      "[[0.6685098 0.7365291 0.6310544 0.8457528]]\n",
      "[0.0]\n",
      "[[0.73984617 0.72178584 0.6523903  0.9099022 ]]\n",
      "[0.0]\n",
      "[[0.76533353 0.7144039  0.6015734  0.84541553]]\n",
      "[0.0]\n",
      "[[0.782032   0.643972   0.6957501  0.77959126]]\n",
      "[0.0]\n",
      "[[0.838928   0.6131705  0.78529125 0.81192917]]\n",
      "[0.0]\n",
      "[[0.8065504 0.6290729 0.7998918 0.8160041]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home_01/f20150198/miniconda2/envs/python3/lib/python3.5/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0]\n",
      "[[0.7409529  0.5808976  0.7846425  0.88829124]]\n",
      "[0.0]\n",
      "[[0.74733645 0.5142567  0.8331797  0.9076777 ]]\n",
      "[0.0]\n",
      "[[0.8102697  0.48122698 0.8590978  0.7904566 ]]\n",
      "[0.0]\n",
      "[[0.81325203 0.46874255 0.77666295 0.8540531 ]]\n",
      "[0.0]\n",
      "[[0.7064181  0.5079763  0.8312063  0.78277177]]\n",
      "[0.0]\n",
      "[[0.63755447 0.61189944 0.7915397  0.81645745]]\n",
      "[0.0]\n",
      "[[0.5445195  0.5961769  0.70658207 0.83601904]]\n",
      "[0.0]\n",
      "[[0.4743866  0.701205   0.6064224  0.86370176]]\n",
      "[0.0]\n",
      "[[0.40045312 0.65019304 0.67927015 0.7715731 ]]\n",
      "[0.0]\n",
      "[[0.37050876 0.6937445  0.6554372  0.67043674]]\n",
      "[0.0]\n",
      "[[0.5078997 0.6232746 0.5644468 0.6444195]]\n",
      "[0.0]\n",
      "[[0.54939175 0.68159044 0.5020418  0.6206587 ]]\n",
      "[0.0]\n",
      "[[0.4665258 0.6735068 0.5793759 0.6797445]]\n",
      "[0.0]\n",
      "[[0.5689952  0.7288696  0.6657643  0.72193027]]\n",
      "[0.0]\n",
      "[[0.5704142 0.6680003 0.7004702 0.6803185]]\n",
      "[0.0]\n",
      "[[0.49517655 0.65994406 0.7722854  0.60972   ]]\n",
      "[0.0]\n",
      "[[0.5277224  0.64232624 0.76135606 0.5493938 ]]\n",
      "[0.0]\n",
      "[[0.6291914  0.602329   0.7681615  0.55399907]]\n",
      "[0.0]\n",
      "[[0.5303191  0.62656444 0.6802281  0.48872983]]\n",
      "[0.0]\n",
      "[[0.44900814 0.566837   0.59902626 0.54930866]]\n",
      "[0.0]\n",
      "[[0.47467345 0.67999685 0.69909257 0.6740823 ]]\n",
      "[0.0]\n",
      "[[0.44141248 0.6705507  0.6489111  0.69910985]]\n",
      "[0.0]\n",
      "[[0.48940253 0.7340295  0.6985194  0.6538267 ]]\n",
      "[0.0]\n",
      "[[0.49025315 0.7342288  0.6018542  0.5730125 ]]\n",
      "[0.0]\n",
      "[[0.4915258  0.65209997 0.66172785 0.5455447 ]]\n",
      "[0.0]\n",
      "[[0.4362452  0.5988054  0.60982835 0.5173231 ]]\n",
      "[0.0]\n",
      "[[0.47382605 0.60963315 0.5784254  0.5763234 ]]\n",
      "[0.0]\n",
      "[[0.44487754 0.7009755  0.6817261  0.6440125 ]]\n",
      "[0.0]\n",
      "[[0.46182805 0.69907534 0.69456506 0.56398094]]\n",
      "[0.0]\n",
      "[[0.46992004 0.70006484 0.6265275  0.50314534]]\n",
      "[0.0]\n",
      "[[0.554699   0.67015237 0.6356202  0.61701053]]\n",
      "[0.0]\n",
      "[[0.5882123  0.632188   0.73548335 0.60269296]]\n",
      "[0.0]\n",
      "[[0.49395832 0.6806175  0.6451774  0.5764834 ]]\n",
      "[0.0]\n",
      "[[0.577346  0.7155346 0.5539438 0.5843191]]\n",
      "[0.0]\n",
      "[[0.5591432  0.70670056 0.5147827  0.6183437 ]]\n",
      "[0.0]\n",
      "[[0.47939262 0.66375893 0.5118321  0.7098604 ]]\n",
      "[0.0]\n",
      "[[0.4134475  0.7195964  0.47156844 0.72396713]]\n",
      "[0.0]\n",
      "[[0.42245713 0.7055639  0.55392456 0.7024281 ]]\n",
      "[0.0]\n",
      "[[0.37421143 0.6257892  0.4917347  0.77583563]]\n",
      "[0.0]\n",
      "[[0.43744624 0.7269157  0.5614633  0.6730929 ]]\n",
      "[0.0]\n",
      "[[0.49215904 0.77844924 0.6306492  0.68083596]]\n",
      "[0.0]\n",
      "[[0.4824446  0.7590497  0.7031449  0.64490783]]\n",
      "[0.0]\n",
      "[[0.514702   0.74958616 0.7902486  0.72004855]]\n",
      "[0.0]\n",
      "[[0.6237567  0.81251794 0.7271201  0.66690755]]\n",
      "[0.0]\n",
      "[[0.6288022  0.74329156 0.70011026 0.71005553]]\n",
      "[0.0]\n",
      "[[0.71362394 0.7490333  0.75728506 0.627882  ]]\n",
      "[0.0]\n",
      "[[0.6712758 0.8374255 0.6720512 0.6213994]]\n",
      "[0.0]\n",
      "[[0.57878685 0.7325179  0.74775887 0.7297473 ]]\n",
      "[0.0]\n",
      "[[0.6145289  0.65340066 0.6938484  0.6686914 ]]\n",
      "[0.0]\n",
      "[[0.64494514 0.694524   0.67985415 0.67698175]]\n",
      "[0.0]\n",
      "[[0.55581135 0.70058537 0.7706193  0.73209596]]\n",
      "[0.0]\n",
      "[[0.4797696  0.7032412  0.79945517 0.67264485]]\n",
      "[0.0]\n",
      "[[0.5764907  0.6965785  0.8173263  0.65444803]]\n",
      "[0.0]\n",
      "[[0.68271446 0.7504064  0.81220585 0.593299  ]]\n",
      "[0.0]\n",
      "[[0.6597075  0.6440968  0.81322104 0.6896436 ]]\n",
      "[0.0]\n",
      "[[0.5888775  0.65329593 0.7929996  0.6765195 ]]\n",
      "[0.0]\n",
      "[[0.63159955 0.7467546  0.8221111  0.6787726 ]]\n",
      "[0.0]\n",
      "[[0.7197887  0.7060529  0.8561332  0.71991783]]\n",
      "[0.0]\n",
      "[[0.7608176  0.7770036  0.77827555 0.74752426]]\n",
      "[0.0]\n",
      "[[0.72686803 0.8034303  0.85477114 0.7719926 ]]\n",
      "[0.0]\n",
      "[[0.6197403  0.7778244  0.86458087 0.8419844 ]]\n",
      "[0.0]\n",
      "[[0.6542193  0.82488674 0.7366686  0.9106234 ]]\n",
      "[0.0]\n",
      "[[0.69668657 0.8221301  0.80656594 0.9554128 ]]\n",
      "[0.0]\n",
      "[[0.6063049  0.8641514  0.83830243 0.8566295 ]]\n",
      "[0.0]\n",
      "[[0.6587394  0.8558878  0.74868    0.89271104]]\n",
      "[0.0]\n",
      "[[0.5785081  0.85499567 0.72356176 0.81262094]]\n",
      "[0.0]\n",
      "[[0.59451264 0.8223637  0.65877265 0.88865894]]\n",
      "[0.0]\n",
      "[[0.505489   0.7014504  0.659601   0.92786866]]\n",
      "[0.0]\n",
      "[[0.54943633 0.75288916 0.6579551  0.9217427 ]]\n",
      "[0.0]\n",
      "[[0.5245001  0.699966   0.6570089  0.79136044]]\n",
      "[0.0]\n",
      "[[0.45534974 0.7478706  0.59629554 0.83127654]]\n",
      "[0.0]\n",
      "[[0.5351119  0.71758246 0.6451563  0.87334085]]\n",
      "[0.0]\n",
      "[[0.6199597 0.6396155 0.5863121 0.8273322]]\n",
      "[0.0]\n",
      "[[0.6087035 0.6062894 0.5073571 0.8230336]]\n",
      "[0.0]\n",
      "[[0.70188963 0.59411013 0.5468336  0.7872674 ]]\n",
      "[0.0]\n",
      "[[0.6816605  0.68581986 0.53152084 0.8104987 ]]\n",
      "[0.0]\n",
      "[[0.6754459 0.699954  0.6327237 0.7140274]]\n",
      "[0.0]\n",
      "[[0.73801476 0.65821075 0.66245186 0.77487403]]\n",
      "[0.0]\n",
      "[[0.7544479 0.6391846 0.7290902 0.6833266]]\n",
      "[0.0]\n",
      "[[0.7627894 0.6215405 0.7256025 0.7560239]]\n",
      "[0.0]\n",
      "[[0.80214036 0.6564183  0.6772315  0.69309556]]\n",
      "[0.0]\n",
      "[[0.7685513  0.60829264 0.62926424 0.7845842 ]]\n",
      "[0.0]\n",
      "[[0.6677546 0.6856875 0.6102708 0.7424029]]\n",
      "[0.0]\n",
      "[[0.6212634  0.6012906  0.61285007 0.66812646]]\n",
      "[0.0]\n",
      "[[0.6022924 0.5704444 0.7027963 0.7582949]]\n",
      "[0.0]\n",
      "[[0.58719957 0.6172405  0.7847486  0.7094732 ]]\n",
      "[0.0]\n",
      "[[0.50972027 0.58037996 0.70211464 0.73926723]]\n",
      "[0.0]\n",
      "[[0.5007297  0.56785965 0.758449   0.6831131 ]]\n",
      "[0.0]\n",
      "[[0.57920873 0.6092517  0.72741055 0.75480616]]\n",
      "[0.0]\n",
      "[[0.553075   0.69612193 0.8083875  0.75069463]]\n",
      "[0.0]\n",
      "[[0.59878033 0.7846762  0.84093857 0.7976847 ]]\n",
      "[0.0]\n",
      "[[0.6727303  0.85842216 0.873115   0.8831817 ]]\n",
      "[0.0]\n",
      "[[0.6237414  0.8592471  0.8823237  0.83549374]]\n",
      "[0.0]\n",
      "[[0.60567015 0.7721738  0.9430222  0.7907749 ]]\n",
      "[0.0]\n",
      "[[0.60829276 0.8424447  0.8355914  0.87451786]]\n",
      "[0.0]\n",
      "[[0.5414399  0.7238951  0.7769988  0.82393795]]\n",
      "[0.0]\n",
      "[[0.6391048 0.7912055 0.8122105 0.7929965]]\n",
      "[0.0]\n",
      "[[0.6472869  0.7200825  0.85699856 0.7571608 ]]\n",
      "[0.0]\n",
      "[[0.60117143 0.7428448  0.7572388  0.71083575]]\n",
      "[0.0]\n",
      "[[0.6907549 0.6553473 0.6707478 0.6488811]]\n",
      "[0.0]\n",
      "[[0.62858325 0.64619726 0.6208695  0.6233336 ]]\n",
      "[0.0]\n",
      "[[0.5741008  0.5996359  0.6535192  0.60146797]]\n",
      "[0.0]\n",
      "[[0.54762584 0.66431105 0.57002234 0.5445404 ]]\n",
      "[0.0]\n",
      "[[0.6222073  0.65666807 0.6409948  0.48862323]]\n",
      "[0.0]\n",
      "[[0.62524015 0.73402697 0.61002994 0.57156503]]\n",
      "[0.0]\n",
      "[[0.6461898  0.7054807  0.7209901  0.57194185]]\n",
      "[0.0]\n",
      "[[0.63570815 0.7242123  0.6780259  0.66385424]]\n",
      "[0.0]\n",
      "[[0.652353   0.7354405  0.68901885 0.7698162 ]]\n",
      "[0.0]\n",
      "[[0.74267375 0.7959578  0.6818275  0.74500084]]\n",
      "[0.0]\n",
      "[[0.72756493 0.69008154 0.6079353  0.8413984 ]]\n",
      "[0.0]\n",
      "[[0.6376139  0.7794633  0.65818524 0.90854466]]\n",
      "[0.0]\n",
      "[[0.55359185 0.731604   0.71994865 0.7844447 ]]\n",
      "[0.0]\n",
      "[[0.49006522 0.6994438  0.64362955 0.7055042 ]]\n",
      "[0.0]\n",
      "[[0.5487009  0.6153246  0.73745394 0.73830885]]\n",
      "[0.0]\n",
      "[[0.4713064 0.7029191 0.6745472 0.7289351]]\n",
      "[0.0]\n",
      "[[0.5090386  0.62565804 0.67346436 0.63698256]]\n",
      "[0.0]\n",
      "[[0.46648562 0.71887213 0.7352115  0.6496038 ]]\n",
      "[0.0]\n",
      "[[0.52726823 0.79180306 0.6510388  0.6539711 ]]\n",
      "[0.0]\n",
      "[[0.46512786 0.70097655 0.57566214 0.60055125]]\n",
      "[0.0]\n",
      "[[0.39629924 0.64027315 0.56826395 0.6393721 ]]\n",
      "[0.0]\n",
      "[[0.49485597 0.72665256 0.6306681  0.650406  ]]\n",
      "[0.0]\n",
      "[[0.5894563  0.65651023 0.558954   0.7169122 ]]\n",
      "[0.0]\n",
      "[[0.6176145  0.6064853  0.5484863  0.67049885]]\n",
      "[0.0]\n",
      "[[0.60417813 0.6035941  0.5481976  0.7364781 ]]\n",
      "[0.0]\n",
      "[[0.66735715 0.6263571  0.5622023  0.6933679 ]]\n",
      "[0.0]\n",
      "[[0.71337074 0.7313697  0.52780324 0.7390496 ]]\n",
      "[0.0]\n",
      "[[0.7367211  0.7564053  0.46013346 0.747427  ]]\n",
      "[0.0]\n",
      "[[0.6582621  0.68568903 0.51344794 0.77311385]]\n",
      "[0.0]\n",
      "[[0.67804    0.73645097 0.58227617 0.762234  ]]\n",
      "[0.0]\n",
      "[[0.58108413 0.7868173  0.66094685 0.8252605 ]]\n",
      "[0.0]\n",
      "[[0.61172247 0.68475187 0.5984754  0.73343354]]\n",
      "[0.0]\n",
      "[[0.64446974 0.6938347  0.5427414  0.8231781 ]]\n",
      "[0.0]\n",
      "[[0.73870885 0.7703849  0.5528222  0.7638296 ]]\n",
      "[0.0]\n",
      "[[0.66606593 0.81949675 0.6098854  0.71081746]]\n",
      "[0.0]\n",
      "[[0.741132   0.81327075 0.6006744  0.6913196 ]]\n",
      "[0.0]\n",
      "[[0.7684692  0.787451   0.64167446 0.6167517 ]]\n",
      "[0.0]\n",
      "[[0.7862664  0.7290705  0.7272833  0.57037085]]\n",
      "[0.0]\n",
      "[[0.72557384 0.7316258  0.69895035 0.5935652 ]]\n",
      "[0.0]\n",
      "[[0.7894964  0.6619847  0.75162953 0.6485658 ]]\n",
      "[0.0]\n",
      "[[0.81302965 0.6563384  0.7330647  0.6225093 ]]\n",
      "[0.0]\n",
      "[[0.7749544  0.6151106  0.66020775 0.6241484 ]]\n",
      "[0.0]\n",
      "[[0.68898505 0.62188655 0.6761744  0.5986252 ]]\n",
      "[0.0]\n",
      "[[0.6125287  0.65100706 0.7486576  0.5617868 ]]\n",
      "[0.0]\n",
      "[[0.63558483 0.6854602  0.8148961  0.6229576 ]]\n",
      "[0.0]\n",
      "[[0.59440243 0.6264759  0.8648046  0.5976241 ]]\n",
      "[0.0]\n",
      "[[0.4977784  0.7101464  0.77993566 0.57861507]]\n",
      "[0.0]\n",
      "[[0.47921073 0.65983456 0.8140847  0.57020825]]\n",
      "[0.0]\n",
      "[[0.48942363 0.6502281  0.8636382  0.49833146]]\n",
      "[0.0]\n",
      "[[0.5281661  0.58631766 0.76461285 0.55448633]]\n",
      "[0.0]\n",
      "[[0.5212565 0.5189225 0.7651711 0.6634394]]\n",
      "[0.0]\n",
      "[[0.56944865 0.54329187 0.8075805  0.75531316]]\n",
      "[0.0]\n",
      "[[0.5091525  0.5221946  0.87848425 0.8327619 ]]\n",
      "[0.0]\n",
      "[[0.46962425 0.58516216 0.920995   0.83166254]]\n",
      "[0.0]\n",
      "[[0.5338718  0.6050434  0.82930017 0.7531845 ]]\n",
      "[0.0]\n",
      "[[0.46082008 0.653338   0.7306597  0.7685388 ]]\n",
      "[0.0]\n",
      "[[0.4615232  0.64770925 0.81472564 0.7338913 ]]\n",
      "[0.0]\n",
      "[[0.47730318 0.6296876  0.73778474 0.67261213]]\n",
      "[0.0]\n",
      "[[0.5008678  0.6995715  0.6490257  0.76754755]]\n",
      "[0.0]\n",
      "[[0.54630834 0.6093229  0.6972339  0.7354009 ]]\n",
      "[0.0]\n",
      "[[0.5553934  0.54460484 0.69330084 0.7296309 ]]\n",
      "[0.0]\n",
      "[[0.62015396 0.58375853 0.7310802  0.77210444]]\n",
      "[0.0]\n",
      "[[0.5641279  0.5018001  0.7189665  0.69048524]]\n",
      "[0.0]\n",
      "[[0.4998293  0.49194977 0.72076946 0.7193159 ]]\n",
      "[0.0]\n",
      "[[0.54600304 0.6091256  0.638112   0.7316728 ]]\n",
      "[0.0]\n",
      "[[0.47201297 0.65612704 0.63631624 0.65885824]]\n",
      "[0.0]\n",
      "[[0.4555329  0.6943678  0.64150524 0.75945204]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0]\n",
      "[[0.45370063 0.66363287 0.7343596  0.77720004]]\n",
      "[0.0]\n",
      "[[0.4035059 0.7287274 0.6958825 0.8585173]]\n",
      "[0.0]\n",
      "[[0.467198   0.7866557  0.76802397 0.8409355 ]]\n",
      "[0.0]\n",
      "[[0.58775574 0.6762049  0.71881235 0.8905943 ]]\n",
      "[0.0]\n",
      "[[0.49699843 0.70813066 0.8098322  0.90579516]]\n",
      "[0.0]\n",
      "[[0.5906999  0.61839104 0.7965996  0.8967821 ]]\n",
      "[0.0]\n",
      "[[0.5832513  0.61321384 0.83441496 0.7985285 ]]\n",
      "[0.0]\n",
      "[[0.49832568 0.6461415  0.90071684 0.8474945 ]]\n",
      "[0.0]\n",
      "[[0.54838914 0.6126234  0.94712454 0.7316787 ]]\n",
      "[0.0]\n",
      "[[0.50459325 0.67981744 0.9873097  0.70764846]]\n",
      "[0.0]\n",
      "[[0.5977207 0.6020306 0.9613768 0.6198901]]\n",
      "[0.0]\n",
      "[[0.5407818  0.5556144  0.82058156 0.6088952 ]]\n",
      "[0.0]\n",
      "[[0.5503154  0.5351446  0.82586074 0.53049725]]\n",
      "[0.0]\n",
      "[[0.563571   0.56160957 0.78529674 0.64175826]]\n",
      "[0.0]\n",
      "[[0.49602282 0.5638357  0.7608103  0.62844443]]\n",
      "[0.0]\n",
      "[[0.6091179  0.59588385 0.75440454 0.6299266 ]]\n",
      "[0.0]\n",
      "[[0.5953264  0.7002824  0.80698216 0.67399615]]\n",
      "[0.0]\n",
      "[[0.5302159  0.71924764 0.7190065  0.6534258 ]]\n",
      "[0.0]\n",
      "[[0.44901875 0.7573373  0.8117942  0.6933038 ]]\n",
      "[0.0]\n",
      "[[0.4922211  0.70139587 0.78004885 0.69067895]]\n",
      "[0.0]\n",
      "[[0.5003447  0.65756506 0.7049757  0.7467743 ]]\n",
      "[0.0]\n",
      "[[0.613816   0.72739476 0.72061956 0.6483145 ]]\n",
      "[0.0]\n",
      "[[0.57805675 0.7861738  0.80544907 0.6661301 ]]\n",
      "[0.0]\n",
      "[[0.6004051  0.8062084  0.73341936 0.7141843 ]]\n",
      "[0.0]\n",
      "[[0.57813305 0.85674053 0.7147164  0.7430795 ]]\n",
      "[0.0]\n",
      "[[0.5971634 0.8409336 0.6969832 0.8250891]]\n",
      "[0.0]\n",
      "[[0.64894444 0.8031786  0.69394964 0.88307637]]\n",
      "[0.0]\n",
      "[[0.6904877  0.8152997  0.78418005 0.7794869 ]]\n",
      "[0.0]\n",
      "[[0.69476354 0.8194388  0.7610558  0.8619938 ]]\n",
      "[0.0]\n",
      "[[0.7712553  0.7782584  0.7739219  0.88927716]]\n",
      "[0.0]\n",
      "[[0.7842076  0.74116045 0.81451875 0.8252007 ]]\n",
      "[0.0]\n",
      "[[0.68744236 0.7676393  0.823848   0.7886686 ]]\n",
      "[0.0]\n",
      "[[0.67537755 0.8508639  0.86447066 0.75975657]]\n",
      "[0.0]\n",
      "[[0.74878633 0.839206   0.81843036 0.7836441 ]]\n",
      "[0.0]\n",
      "[[0.78454655 0.89562094 0.83441573 0.8087757 ]]\n",
      "[0.0]\n",
      "[[0.7373076  0.77366656 0.8081926  0.71970546]]\n",
      "[0.0]\n",
      "[[0.80722415 0.7346826  0.81389666 0.7688083 ]]\n",
      "[0.0]\n",
      "[[0.7172553  0.7963858  0.7621292  0.67962795]]\n",
      "[0.0]\n",
      "[[0.72619    0.76521504 0.8324479  0.6749434 ]]\n",
      "[0.0]\n",
      "[[0.6335705  0.66005117 0.71026295 0.68204856]]\n",
      "[0.0]\n",
      "[[0.6786301  0.5737254  0.66819304 0.68261474]]\n",
      "[0.0]\n",
      "[[0.7522539  0.6803952  0.7412532  0.71346533]]\n",
      "[0.0]\n",
      "[[0.74931335 0.6236497  0.75216895 0.64488566]]\n",
      "[0.0]\n",
      "[[0.69227487 0.6991446  0.7523254  0.69740087]]\n",
      "[0.0]\n",
      "[[0.6756549 0.6558282 0.7379815 0.7102522]]\n",
      "[0.0]\n",
      "[[0.61263144 0.7310676  0.82478374 0.64416057]]\n",
      "[0.0]\n",
      "[[0.5587282  0.78542846 0.8483258  0.59808165]]\n",
      "[0.0]\n",
      "[[0.57902914 0.71679896 0.89634407 0.63110054]]\n",
      "[0.0]\n",
      "[[0.5823306 0.6466945 0.8447074 0.6315575]]\n",
      "[0.0]\n",
      "[[0.5570169 0.5934806 0.7547185 0.6777959]]\n",
      "[0.0]\n",
      "[[0.65109646 0.675878   0.76664656 0.7419455 ]]\n",
      "[0.0]\n",
      "[[0.571171  0.617694  0.7951604 0.638967 ]]\n",
      "[0.0]\n",
      "[[0.49454913 0.68362683 0.7190707  0.5878919 ]]\n",
      "[0.0]\n",
      "[[0.48934218 0.751764   0.619019   0.6847121 ]]\n",
      "[0.0]\n",
      "[[0.46785888 0.7579008  0.6291232  0.61671776]]\n",
      "[0.0]\n",
      "[[0.58355993 0.68395    0.7009489  0.7104763 ]]\n",
      "[0.0]\n",
      "[[0.5826833 0.7805266 0.6115431 0.642651 ]]\n",
      "[0.0]\n",
      "[[0.589424   0.6856172  0.6810495  0.66040933]]\n",
      "[0.0]\n",
      "[[0.659097   0.64417636 0.5801197  0.7481759 ]]\n",
      "[0.0]\n",
      "[[0.5981456  0.63123053 0.5169628  0.75895864]]\n",
      "[0.0]\n",
      "[[0.59590816 0.5764542  0.44604567 0.71807986]]\n",
      "[0.0]\n",
      "[[0.6582239 0.5223285 0.4238203 0.737638 ]]\n",
      "[0.0]\n",
      "[[0.6817552  0.60961103 0.48676977 0.80033153]]\n",
      "[0.0]\n",
      "[[0.6019965  0.70764863 0.41978124 0.70665735]]\n",
      "[0.0]\n",
      "[[0.5218054  0.7585248  0.46020317 0.7901343 ]]\n",
      "[0.0]\n",
      "[[0.62583846 0.83630425 0.5173584  0.7484401 ]]\n",
      "[0.0]\n",
      "[[0.7109905  0.86105263 0.48142415 0.7493608 ]]\n",
      "[0.0]\n",
      "[[0.59823084 0.74291176 0.5345746  0.7801805 ]]\n",
      "[0.0]\n",
      "[[0.67216337 0.78792053 0.4823549  0.8163253 ]]\n",
      "[0.0]\n",
      "[[0.7590596  0.80597365 0.5098967  0.7603326 ]]\n",
      "[0.0]\n",
      "[[0.6499969 0.8119472 0.6287672 0.6784148]]\n",
      "[0.0]\n",
      "[[0.7081362  0.8726782  0.6095362  0.75507843]]\n",
      "[0.0]\n",
      "[[0.62295127 0.80651915 0.63911176 0.82726   ]]\n",
      "[0.0]\n",
      "[[0.62868965 0.7073517  0.73574436 0.82808554]]\n",
      "[0.0]\n",
      "[[0.686232   0.65290916 0.6974802  0.7323088 ]]\n",
      "[0.0]\n",
      "[[0.61764914 0.6498334  0.6751448  0.7621348 ]]\n",
      "[0.0]\n",
      "[[0.6891657  0.6236084  0.7550241  0.78818154]]\n",
      "[0.0]\n",
      "[[0.6515536  0.5687901  0.83186567 0.80891776]]\n",
      "[0.0]\n",
      "[[0.5578333  0.61924994 0.78140444 0.777087  ]]\n",
      "[0.0]\n",
      "[[0.62259966 0.5721324  0.71786827 0.77362263]]\n",
      "[0.0]\n",
      "[[0.704733   0.50697184 0.7757589  0.80556065]]\n",
      "[0.0]\n",
      "[[0.6283745 0.5683456 0.7820242 0.8296634]]\n",
      "[0.0]\n",
      "[[0.63167703 0.5505217  0.7665806  0.7564258 ]]\n",
      "[0.0]\n",
      "[[0.61758703 0.5504978  0.675888   0.695159  ]]\n",
      "[0.0]\n",
      "[[0.5799471 0.5479633 0.6895109 0.7449389]]\n",
      "[0.0]\n",
      "[[0.532419   0.582952   0.65385336 0.67743146]]\n",
      "[0.0]\n",
      "[[0.471785   0.6954473  0.7399581  0.74404776]]\n",
      "[0.0]\n",
      "[[0.42747116 0.62406975 0.6526106  0.7012115 ]]\n",
      "[0.0]\n",
      "[[0.44001877 0.53274554 0.64179206 0.7428966 ]]\n",
      "[0.0]\n",
      "[[0.5333865  0.49287093 0.5508073  0.79852057]]\n",
      "[0.0]\n",
      "[[0.5186042  0.48471263 0.50552946 0.7413447 ]]\n",
      "[0.0]\n",
      "[[0.48530674 0.46840632 0.48381203 0.7441253 ]]\n",
      "[0.0]\n",
      "[[0.57061064 0.46572363 0.5003083  0.7406274 ]]\n",
      "[0.0]\n",
      "[[0.6515558 0.5574059 0.621761  0.6728042]]\n",
      "[0.0]\n",
      "[[0.71262467 0.53806776 0.639627   0.68596977]]\n",
      "[0.0]\n",
      "[[0.7177642  0.5230968  0.5558863  0.59270597]]\n",
      "[0.0]\n",
      "[[0.7906596  0.6214038  0.56353617 0.5271574 ]]\n",
      "[0.0]\n",
      "[[0.83571947 0.6295802  0.57289404 0.580369  ]]\n",
      "[0.0]\n",
      "[[0.73650813 0.58281463 0.6480044  0.64375174]]\n",
      "[0.0]\n",
      "[[0.81629074 0.5876937  0.7434325  0.72783375]]\n",
      "[0.0]\n",
      "[[0.78509516 0.6821987  0.66632986 0.6358542 ]]\n",
      "[0.0]\n",
      "[[0.819038  0.6088269 0.6725034 0.6935475]]\n",
      "[0.0]\n",
      "[[0.8176615 0.5639254 0.7324044 0.6017296]]\n",
      "[0.0]\n",
      "[[0.7958559  0.6651145  0.73114276 0.5710254 ]]\n",
      "[0.0]\n",
      "[[0.86770916 0.71836174 0.7794351  0.6687827 ]]\n",
      "[0.0]\n",
      "[[0.91671157 0.7274814  0.8305885  0.6775908 ]]\n",
      "[0.0]\n",
      "[[0.82140636 0.6747201  0.76068485 0.5903549 ]]\n",
      "[0.0]\n",
      "[[0.81469756 0.65597403 0.833027   0.5206404 ]]\n",
      "[0.0]\n",
      "[[0.83874017 0.6001805  0.77838564 0.5104158 ]]\n",
      "[0.0]\n",
      "[[0.8958512  0.6432299  0.76169795 0.4802669 ]]\n",
      "[0.0]\n",
      "[[0.7656179 0.6252053 0.8477865 0.507718 ]]\n",
      "[0.0]\n",
      "[[0.7822305  0.71497214 0.73076016 0.50575924]]\n",
      "[0.0]\n",
      "[[0.7465949  0.6594787  0.6944868  0.57512593]]\n",
      "[0.0]\n",
      "[[0.65854186 0.7013842  0.6465244  0.62895024]]\n",
      "[0.0]\n",
      "[[0.5900829  0.75319463 0.63301015 0.7067858 ]]\n",
      "[0.0]\n",
      "[[0.6920307  0.75709206 0.54245013 0.6789676 ]]\n",
      "[0.0]\n",
      "[[0.7772447  0.77732193 0.6114411  0.67605144]]\n",
      "[0.0]\n",
      "[[0.84249884 0.84800386 0.64068425 0.69627225]]\n",
      "[0.0]\n",
      "[[0.72754025 0.72750545 0.58675486 0.7390433 ]]\n",
      "[0.0]\n",
      "[[0.77800494 0.7733242  0.6796483  0.6386712 ]]\n",
      "[0.0]\n",
      "[[0.6531019  0.70979077 0.5840598  0.6650493 ]]\n",
      "[0.0]\n",
      "[[0.72710836 0.78913826 0.5199885  0.6988421 ]]\n",
      "[0.0]\n",
      "[[0.74328816 0.8090774  0.52206254 0.64286023]]\n",
      "[0.0]\n",
      "[[0.8008332  0.8718041  0.58917505 0.6620519 ]]\n",
      "[0.0]\n",
      "[[0.6792759  0.79763377 0.5506331  0.62096155]]\n",
      "[0.0]\n",
      "[[0.61321765 0.8132623  0.6076144  0.57209   ]]\n",
      "[0.0]\n",
      "[[0.69156134 0.69400537 0.71260566 0.61110324]]\n",
      "[0.0]\n",
      "[[0.7086887  0.65034664 0.7502709  0.70439816]]\n",
      "[0.0]\n",
      "[[0.6373517 0.5844083 0.8005721 0.6584394]]\n",
      "[0.0]\n",
      "[[0.55841595 0.60237616 0.719595   0.61270505]]\n",
      "[0.0]\n",
      "[[0.5297431  0.5365767  0.77313703 0.6433116 ]]\n",
      "[0.0]\n",
      "[[0.5783556  0.5178905  0.80900466 0.7469661 ]]\n",
      "[0.0]\n",
      "[[0.686766   0.4492158  0.7487123  0.65907425]]\n",
      "[0.0]\n",
      "[[0.67527556 0.5136411  0.75726855 0.63660574]]\n",
      "[0.0]\n",
      "[[0.76152176 0.5636787  0.84256816 0.6299681 ]]\n",
      "[0.0]\n",
      "[[0.77054083 0.5051347  0.8207209  0.66812694]]\n",
      "[0.0]\n",
      "[[0.693684   0.5600156  0.72427094 0.66266114]]\n",
      "[0.0]\n",
      "[[0.7005774  0.57475376 0.6488139  0.60465646]]\n",
      "[0.0]\n",
      "[[0.65641546 0.6193745  0.6416379  0.56044835]]\n",
      "[0.0]\n",
      "[[0.6103862  0.5931356  0.57538545 0.59433687]]\n",
      "[0.0]\n",
      "[[0.60335875 0.5760539  0.4879118  0.68886155]]\n",
      "[0.0]\n",
      "[[0.51420456 0.51613754 0.47576    0.7506386 ]]\n",
      "[0.0]\n",
      "[[0.61602557 0.59138286 0.44739676 0.8154957 ]]\n",
      "[0.0]\n",
      "[[0.52298445 0.5264005  0.4059294  0.8149892 ]]\n",
      "[0.0]\n",
      "[[0.5528237  0.57607913 0.54054165 0.85235494]]\n",
      "[0.0]\n",
      "[[0.6107753  0.52874434 0.6483952  0.9187792 ]]\n",
      "[0.0]\n",
      "[[0.67994934 0.47077882 0.69903207 0.89565253]]\n",
      "[0.0]\n",
      "[[0.68216014 0.46125752 0.74833065 0.9322209 ]]\n",
      "[0.0]\n",
      "[[0.73180395 0.45930105 0.78050876 0.8184081 ]]\n",
      "[0.0]\n",
      "[[0.75478077 0.3984109  0.6617457  0.72509134]]\n",
      "[0.0]\n",
      "[[0.767373  0.5350676 0.6553717 0.7512006]]\n",
      "[0.0]\n",
      "[[0.76621133 0.62428707 0.75143915 0.8073988 ]]\n",
      "[0.0]\n",
      "[[0.71177167 0.5486412  0.8166774  0.74571246]]\n",
      "[0.0]\n",
      "[[0.7505126  0.64563465 0.72614753 0.67625403]]\n",
      "[0.0]\n",
      "[[0.71332335 0.72316676 0.7878755  0.77611923]]\n",
      "[0.0]\n",
      "[[0.65039873 0.74060863 0.8477351  0.7393383 ]]\n",
      "[0.0]\n",
      "[[0.6562243  0.67563856 0.89451694 0.72225285]]\n",
      "[0.0]\n",
      "[[0.64105296 0.71101034 0.826885   0.77707016]]\n",
      "[0.0]\n",
      "[[0.6271203  0.6969707  0.84618765 0.79621494]]\n",
      "[0.0]\n",
      "[[0.6670226  0.7700198  0.8832059  0.76592547]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8a8ef64219a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mddpg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-8a8ef64219a2>\u001b[0m in \u001b[0;36mddpg\u001b[0;34m(n_episodes, max_t, print_every)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0menv_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[0;34m]\u001b[0m           \u001b[0;31m# send all actions to tne environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_observations\u001b[0m         \u001b[0;31m# get next state (for each agent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#             print(next_state)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/python3/lib/python3.5/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, vector_action, memory, text_action)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             outputs = self.communicator.exchange(\n\u001b[0;32m--> 369\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_step_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m             )\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/python3/lib/python3.5/site-packages/unityagents/rpc_communicator.py\u001b[0m in \u001b[0;36mexchange\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/python3/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/python3/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/python3/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "from ddpg_agent import Agent\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "env = UnityEnvironment(file_name='Reacher_Linux_NoVis/Reacher.x86_64')\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "print(\"episode done \",env_info.local_done)\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "agent = Agent(state_size=state_size, action_size=action_size, random_seed=2)\n",
    "#scores = np.zeros(1)                          # initialize the score (for each agent)\n",
    "print(\"hello\")\n",
    "def ddpg(n_episodes=5000, max_t=2000, print_every=100):\n",
    "    scores_deque = deque(maxlen=print_every)\n",
    "    scores = []\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        #/print(\"mello\")\n",
    "        env_info = env.reset(train_mode=True)[brain_name]     # reset the environment\n",
    "        #print(\"kello\")\n",
    "        state = env_info.vector_observations                 # get the current state (for each agent)\n",
    "       # print(state.shape,\"first\")\n",
    "        score = [0]\n",
    "       # print(\"maxt\",max_t)\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state)\n",
    "            print(action)\n",
    "            env_info = env.step(action)[brain_name]           # send all actions to tne environment\n",
    "            next_state = env_info.vector_observations         # get next state (for each agent)\n",
    "#             print(next_state)\n",
    "            reward = env_info.rewards                        # get reward (for each agent)\n",
    "#             print(reward)\n",
    "            done = env_info.local_done                        # see if episode finished\n",
    "           # print(len(done))\n",
    "#             print(done)\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            print(reward)\n",
    "            score += reward\n",
    "           # print(t,\"time\")\n",
    "           # print(\"score\",score)\n",
    "        avg_score = np.mean(score)\n",
    "        scores_deque.append(avg_score)\n",
    "        scores.append(avg_score)\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)), end=\"\")\n",
    "        if np.mean(scores_deque) >= 30.0:\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "            break\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "            \n",
    "    return scores\n",
    "\n",
    "scores = ddpg()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
